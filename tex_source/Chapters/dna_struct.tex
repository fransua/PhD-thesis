%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../master"
%%% End: 

\section{Introduction}

From a biological perspective it seems obvious that DNA is something else than random mix of A, T, G or C nucleotides. Genomes are composed of functional elements as can be genes or promoters but also repetitive elements that by definition can not be random when taken together. However to what extent can we state that genomes are not a random soup of 4 letters? 

This question could be solved in some sense by measuring genomes entropy. This measure presents the disadvantage that extreme cases of high entropy could correspond to \begin{inparaenum}[\itshape a\upshape)] \item {\bf a specially high content of information}, entropy-based algorithms are actually used to predict or confirm automatic detection of genes \cite{Du2006,Gerstein2007}, \item {\bf an exact random structure}, some work in the sense of testing the random structure of DNA have been done using entropy \cite{Loewenstern1999}. \end{inparaenum} However this characteristic of entropy could be only a semantic problem if we use it as a measure of relative variation in DNA complexity in genomes, and try to discern statistical patterns in the DNA sequences of different genomic element such as interspersed repeats or functional element (like protein-coding genes). This kind of description of DNA sequence complexity was already done by \cite{Holste2001}, but only in human chromosome 22.



\section{Results and Discussion}
\section{Material and methods}

\subsection{The complexity ratio and complexity value}

Complexity Ratio (CR) is defined by a classical formula used in data compression \cite{Adjeroh2008}, the Burros-Wheeler transform BWT \cite{Burrows1994}, followed by the Move To Front (MFT) \cite{Ryabko1980} and finally resume this to one value using Shannon's entropy \cite{Shannon1948}


\subsection{Complexity in strings}

\subsection{Simulations}
